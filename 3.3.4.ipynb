{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Vanilla vs Ridge vs Lasso logistic regression\n",
    "\n",
    "## Dataset\n",
    "The [crime rates in 2013](https://ucr.fbi.gov/crime-in-the-u.s/2013/crime-in-the-u.s.-2013/tables/table-8/table_8_offenses_known_to_law_enforcement_by_state_by_city_2013.xls/view) dataset, including all states, 9281 entries in total.\n",
    "\n",
    "First, load the data and do a little cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data.\n",
    "df = pd.read_excel('Table_8_Offenses_Known_to_Law_Enforcement_by_State_by_City_2013.xls',\n",
    "                   skipinitialspace=True, header=3)\n",
    "df.drop(['State', 'City', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16'], axis=1, inplace=True)\n",
    "\n",
    "# Cleaning data.\n",
    "df.columns = ['population', 'violent_crime', 'murder', 'rape_1',\n",
    "               'rape_2', 'robbery', 'assault', 'property_crime', 'burglary',\n",
    "               'larceny', 'vehicle_theft', 'arson']\n",
    "\n",
    "df[['rape_1', 'rape_2', 'arson']] = df[['rape_1', 'rape_2', 'arson']].fillna(0)\n",
    "df['rape'] = df['rape_1'] + df['rape_2']\n",
    "\n",
    "df = df[:-10]\n",
    "df.dropna(inplace=True)\n",
    "df.drop(['rape_1', 'rape_2'], axis=1, inplace=True)\n",
    "\n",
    "# Make assault the outcome variable.\n",
    "df['assault'] = np.where(df['assault'] == 0, 0, 1)\n",
    "\n",
    "# Creating training set and test set.\n",
    "X = df.loc[:, ~(df.columns).isin(['assault'])]\n",
    "Y = df['assault']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla logistic regression (using statsmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.010751\n",
      "         Iterations: 35\n",
      "         Function evaluations: 54\n",
      "         Gradient evaluations: 45\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                assault   No. Observations:                 6496\n",
      "Model:                          Logit   Df Residuals:                     6486\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Sun, 29 Jul 2018   Pseudo R-squ.:                  0.9751\n",
      "Time:                        16:32:10   Log-Likelihood:                -69.840\n",
      "converged:                      False   LL-Null:                       -2805.2\n",
      "                                        LLR p-value:                     0.000\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "population         0.0003   8.71e-05      2.918      0.004    8.35e-05       0.000\n",
      "violent_crime     14.7091      2.350      6.258      0.000      10.103      19.316\n",
      "murder           -13.8901      2.822     -4.922      0.000     -19.422      -8.359\n",
      "robbery          -14.9897      2.425     -6.182      0.000     -19.742     -10.237\n",
      "property_crime    -0.0783   1.01e+05  -7.78e-07      1.000   -1.97e+05    1.97e+05\n",
      "burglary           0.1145   1.01e+05   1.14e-06      1.000   -1.97e+05    1.97e+05\n",
      "larceny            0.0857   1.01e+05   8.52e-07      1.000   -1.97e+05    1.97e+05\n",
      "vehicle_theft     -0.2785   1.01e+05  -2.77e-06      1.000   -1.97e+05    1.97e+05\n",
      "arson              1.0115      0.532      1.902      0.057      -0.031       2.054\n",
      "rape             -11.8362      1.708     -6.932      0.000     -15.183      -8.489\n",
      "intercept        -11.2187      2.396     -4.682      0.000     -15.915      -6.522\n",
      "==================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.89 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      " Accuracy by assault status\n",
      "assault    0     1\n",
      "row_0             \n",
      "0        415     0\n",
      "1          4  2366\n",
      "\n",
      " Percentage accuracy\n",
      "0.9985637342908438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1674: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1724: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1674: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1724: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Vanilla logistic regression.\n",
    "X_vlr_train = X_train.copy()\n",
    "X_vlr_train['intercept'] = 1\n",
    "Y_vlr_train = pd.DataFrame(Y_train)\n",
    "\n",
    "vlr = sm.Logit(Y_vlr_train, X_vlr_train)\n",
    "result = vlr.fit(method='bfgs')\n",
    "print(result.summary())\n",
    "\n",
    "# Check accuracy\n",
    "X_vlr_test = X_test.copy()\n",
    "X_vlr_test['intercept'] = 1\n",
    "\n",
    "pred_vlr = result.predict(X_vlr_test)\n",
    "pred_y_vlr = np.where(pred_vlr < .5, 0, 1)\n",
    "\n",
    "print('\\n Accuracy by assault status')\n",
    "table = pd.crosstab(pred_y_vlr, Y_test)\n",
    "print(table)\n",
    "print('\\n Percentage accuracy')\n",
    "print((table.iloc[0,0] + table.iloc[1,1]) / (table.sum().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge logistic regression (sklearn with L2 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set accuracy:  0.958743842364532\n",
      "\n",
      "Test set accuracy:  0.9583482944344703\n",
      "\n",
      " Accuracy by assault status\n",
      "assault    0     1\n",
      "row_0             \n",
      "0        325    22\n",
      "1         94  2344\n"
     ]
    }
   ],
   "source": [
    "# Ridge logistic regression.\n",
    "rlr = LogisticRegression(penalty='l2')\n",
    "rlr_fit = rlr.fit(X_train, Y_train)\n",
    "print('\\nTraining set accuracy: ', rlr.score(X_train, Y_train))\n",
    "print('\\nTest set accuracy: ', rlr.score(X_test, Y_test))\n",
    "\n",
    "pred_y_test = rlr.predict(X_test)\n",
    "print('\\n Accuracy by assault status')\n",
    "print(pd.crosstab(pred_y_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso logistic regression (sklearn with L1 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set accuracy:  0.8445197044334976\n",
      "\n",
      "Test set accuracy:  0.8495511669658887\n",
      "\n",
      " Accuracy by assault status\n",
      "assault    0     1\n",
      "row_0             \n",
      "1        419  2366\n"
     ]
    }
   ],
   "source": [
    "# Lasso logistic regression.\n",
    "llr = LogisticRegression(penalty='l1')\n",
    "llr_fit = llr.fit(X_train, Y_train)\n",
    "print('\\nTraining set accuracy: ', llr.score(X_train, Y_train))\n",
    "print('\\nTest set accuracy: ', llr.score(X_test, Y_test))\n",
    "\n",
    "pred_y_test = llr.predict(X_test)\n",
    "print('\\n Accuracy by assault status')\n",
    "print(pd.crosstab(pred_y_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q: Do we need to define C when using ridge or lasso logistic regression? Is it the same as lambda? What is the best way to determine C?__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
